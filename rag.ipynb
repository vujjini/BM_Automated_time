{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRXpZWL8GV2P",
        "outputId": "32a1c916-4417-42fc-d0a5-1f03ed534b5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rT7RYseFQOSpTlX4LQyb7fw42tiESXms"
      ],
      "metadata": {
        "id": "jtGYscekbWFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "lvooF1oSYeF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "F_dZy6QqX9_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-mistralai"
      ],
      "metadata": {
        "id": "U9TJI2nJKBqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"MISTRAL_API_KEY\"):\n",
        "  os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter API key for Mistral AI: \")\n",
        "\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "llm = ChatMistralAI(model=\"mistral-large-latest\")\n"
      ],
      "metadata": {
        "id": "E6stW8DfJ9YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import MistralAIEmbeddings\n",
        "\n",
        "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJDVrFIfKRGK",
        "outputId": "3376551e-1783-4bcb-e390-d2824b207926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_mistralai/embeddings.py:180: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "\n"
      ],
      "metadata": {
        "id": "UTkx1p5rcFjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU pypdf"
      ],
      "metadata": {
        "id": "aObk4sLbacex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938afe9f-ed63-452e-d85a-12fbe53ec618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/298.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSQ4gi02jFUr",
        "outputId": "511c98c5-7c3e-4b10-9d7d-8b5ed1077822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/BM Handbook 22-23.pdf\""
      ],
      "metadata": {
        "id": "APwgGdE1G5tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages = []"
      ],
      "metadata": {
        "id": "L56oVK84MzN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(file_path)\n",
        "async for page in loader.alazy_load():\n",
        "    pages.append(page)\n"
      ],
      "metadata": {
        "id": "Wbopau62Gpdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"{pages[0].metadata}\\n\")\n",
        "# print(pages[10].page_content)\n",
        "print(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gjkRzN6HFuP",
        "outputId": "3458e89a-66ed-4859-ccd5-c584c6375899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openpyxl\n",
        "\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "def extract_info(wb):\n",
        "    # Load the workbook\n",
        "    extracted_data = []\n",
        "\n",
        "    # Iterate through all sheets\n",
        "    for sheet_name in wb.sheetnames:\n",
        "        sheet = wb[sheet_name]\n",
        "\n",
        "        found = False\n",
        "        # Iterate through all cells in the sheet\n",
        "        for row in sheet.iter_rows(values_only=True):\n",
        "            if found:\n",
        "                # Append rows after the \"additional notes\" cell\n",
        "                filtered_row = [cell for cell in row if cell is not None]\n",
        "                if filtered_row:  # Only add non-empty rows\n",
        "                    # print(filtered_row)\n",
        "                    extracted_data.append(filtered_row)\n",
        "            else:\n",
        "                # Check for \"additional notes\" in any cell of the row (case-sensitive)\n",
        "                if any(cell and isinstance(cell, str) and \"additional notes:\" in cell.lower() for cell in row):\n",
        "                    found = True\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/logs'\n",
        "extracted_data = []\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.xlsx'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        workbook = openpyxl.load_workbook(file_path)\n",
        "        data = extract_info(workbook)\n",
        "        extracted_data.append(data)\n",
        "\n",
        "# Create PDF with extracted data\n",
        "# def save_to_pdf(data, output_pdf):\n",
        "#     pdf = FPDF()\n",
        "#     pdf.add_page()\n",
        "#     pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "#     for row in data:\n",
        "#         # Join the row elements with tabs or spaces and add to the PDF\n",
        "#         line = \"\\t\".join(str(row))\n",
        "#         pdf.cell(0, 10, txt=line, ln=True)\n",
        "\n",
        "#     pdf.output(output_pdf)\n",
        "\n",
        "# save_to_pdf(extracted_data, 'output.pdf')\n",
        "# print(f\"Data successfully written to 'output.pdf'\")\n",
        "print(extracted_data[-1][-1][-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNfekC3vjSk_",
        "outputId": "4f001ff1-4b3c-4796-dca1-9d5d05ab776d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 am: Banquest table cloths were not found in the ballroom storage for the ballroom prefunction setup. BM left a note for the next morning BM about it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n"
      ],
      "metadata": {
        "id": "PMZGywDobusI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "JCBvjgkJbvlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "additional_documents = []\n",
        "\n",
        "for log in extracted_data:\n",
        "  for sentence_group in log:\n",
        "      combined_text = \" \".join(sentence_group)  # Combine the sentences into a single string\n",
        "      additional_documents.append(Document(page_content=combined_text))\n",
        "\n",
        "# Add the additional_documents to the existing splits.\n",
        "all_splits.extend(additional_documents)"
      ],
      "metadata": {
        "id": "JPZe0U6AE1C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_splits[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxXQrdC0F8En",
        "outputId": "579f113a-5df1-4cdd-9874-39596a06a088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='12 am: Banquest table cloths were not found in the ballroom storage for the ballroom prefunction setup. BM left a note for the next morning BM about it.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_list(data, chunk_size):\n",
        "    for i in range(0, len(data), chunk_size):\n",
        "        yield data[i:i + chunk_size]"
      ],
      "metadata": {
        "id": "DEQscPFceYMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "for chunk in chunk_list(all_splits, 15):\n",
        "    vector_store.add_documents(documents=chunk)\n",
        "    time.sleep(10)"
      ],
      "metadata": {
        "id": "aclg4DwBez-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# _ = vector_store.add_documents(documents=all_splits[55:80])\n",
        "\n",
        "# Define prompt for question-answering\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n"
      ],
      "metadata": {
        "id": "ofucdY3lb5TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define state for application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Define application steps\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "\n",
        "# Compile application and test\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()\n",
        "\n"
      ],
      "metadata": {
        "id": "EBEkMLViduQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"a client is showing movies in their event? Is that okay?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nghLPX93eP7O",
        "outputId": "e96596ef-51c0-4b3d-d366-e8ea37d6e1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know. The context does not provide information about whether a client is allowed to show movies during their event.\n"
          ]
        }
      ]
    }
  ]
}